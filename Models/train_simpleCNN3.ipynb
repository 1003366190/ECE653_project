{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTrSf0soTX6g"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnVwUM3wTkql",
    "outputId": "571cb38c-5878-4722-84b7-3df5ec73653c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (50000, 1)\n",
      "Shape after one-hot encoding:  (50000, 10)\n",
      "Epoch 1/50\n",
      "500/500 [==============================] - 68s 128ms/step - loss: 2.0979 - accuracy: 0.4198 - val_loss: 2.5100 - val_accuracy: 0.3051\n",
      "Epoch 2/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.7855 - accuracy: 0.5035 - val_loss: 1.8047 - val_accuracy: 0.4962\n",
      "Epoch 3/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.7103 - accuracy: 0.5363 - val_loss: 2.1660 - val_accuracy: 0.4205\n",
      "Epoch 4/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.6917 - accuracy: 0.5582 - val_loss: 2.3136 - val_accuracy: 0.4510\n",
      "Epoch 5/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.6799 - accuracy: 0.5745 - val_loss: 1.6335 - val_accuracy: 0.5938\n",
      "Epoch 6/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.6644 - accuracy: 0.5856 - val_loss: 1.8390 - val_accuracy: 0.5468\n",
      "Epoch 7/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.6607 - accuracy: 0.5899 - val_loss: 1.7964 - val_accuracy: 0.5626\n",
      "Epoch 8/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.6509 - accuracy: 0.5965 - val_loss: 1.6126 - val_accuracy: 0.6138\n",
      "Epoch 9/50\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 1.6323 - accuracy: 0.6083 - val_loss: 1.8909 - val_accuracy: 0.5422\n",
      "Epoch 10/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.6311 - accuracy: 0.6133 - val_loss: 2.1648 - val_accuracy: 0.4608\n",
      "Epoch 11/50\n",
      "500/500 [==============================] - 64s 129ms/step - loss: 1.6107 - accuracy: 0.6198 - val_loss: 2.0244 - val_accuracy: 0.5020\n",
      "Epoch 12/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.5989 - accuracy: 0.6211 - val_loss: 1.5823 - val_accuracy: 0.6298\n",
      "Epoch 13/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.5894 - accuracy: 0.6277 - val_loss: 1.8432 - val_accuracy: 0.5544\n",
      "Epoch 14/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.5631 - accuracy: 0.6323 - val_loss: 1.5290 - val_accuracy: 0.6458\n",
      "Epoch 15/50\n",
      "500/500 [==============================] - 64s 128ms/step - loss: 1.5590 - accuracy: 0.6363 - val_loss: 1.7508 - val_accuracy: 0.5712\n",
      "Epoch 16/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.5424 - accuracy: 0.6413 - val_loss: 1.7595 - val_accuracy: 0.5798\n",
      "Epoch 17/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.5237 - accuracy: 0.6455 - val_loss: 1.7804 - val_accuracy: 0.5740\n",
      "Epoch 18/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.5120 - accuracy: 0.6467 - val_loss: 1.6846 - val_accuracy: 0.5914\n",
      "Epoch 19/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.4916 - accuracy: 0.6483 - val_loss: 1.5416 - val_accuracy: 0.6347\n",
      "Epoch 20/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.4753 - accuracy: 0.6540 - val_loss: 1.5731 - val_accuracy: 0.6149\n",
      "Epoch 21/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.4678 - accuracy: 0.6537 - val_loss: 1.7165 - val_accuracy: 0.5767\n",
      "Epoch 22/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.4646 - accuracy: 0.6559 - val_loss: 1.9854 - val_accuracy: 0.4975\n",
      "Epoch 23/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.4405 - accuracy: 0.6591 - val_loss: 1.5008 - val_accuracy: 0.6379\n",
      "Epoch 24/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.4247 - accuracy: 0.6583 - val_loss: 1.5724 - val_accuracy: 0.6082\n",
      "Epoch 25/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.4273 - accuracy: 0.6619 - val_loss: 1.7546 - val_accuracy: 0.5560\n",
      "Epoch 26/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.4140 - accuracy: 0.6620 - val_loss: 1.6928 - val_accuracy: 0.5889\n",
      "Epoch 27/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.4070 - accuracy: 0.6659 - val_loss: 1.4678 - val_accuracy: 0.6434\n",
      "Epoch 28/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3895 - accuracy: 0.6643 - val_loss: 1.4114 - val_accuracy: 0.6572\n",
      "Epoch 29/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3714 - accuracy: 0.6666 - val_loss: 1.5434 - val_accuracy: 0.6038\n",
      "Epoch 30/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.3553 - accuracy: 0.6709 - val_loss: 1.4424 - val_accuracy: 0.6408\n",
      "Epoch 31/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3475 - accuracy: 0.6719 - val_loss: 1.7137 - val_accuracy: 0.5619\n",
      "Epoch 32/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3455 - accuracy: 0.6680 - val_loss: 1.9839 - val_accuracy: 0.4753\n",
      "Epoch 33/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3333 - accuracy: 0.6744 - val_loss: 1.5314 - val_accuracy: 0.6078\n",
      "Epoch 34/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3255 - accuracy: 0.6730 - val_loss: 1.3833 - val_accuracy: 0.6548\n",
      "Epoch 35/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3179 - accuracy: 0.6735 - val_loss: 1.4132 - val_accuracy: 0.6408\n",
      "Epoch 36/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.3115 - accuracy: 0.6774 - val_loss: 1.3397 - val_accuracy: 0.6648\n",
      "Epoch 37/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.3021 - accuracy: 0.6757 - val_loss: 1.3761 - val_accuracy: 0.6530\n",
      "Epoch 38/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2929 - accuracy: 0.6783 - val_loss: 1.5909 - val_accuracy: 0.5807\n",
      "Epoch 39/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2950 - accuracy: 0.6770 - val_loss: 1.3307 - val_accuracy: 0.6644\n",
      "Epoch 40/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2943 - accuracy: 0.6784 - val_loss: 1.3564 - val_accuracy: 0.6573\n",
      "Epoch 41/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2869 - accuracy: 0.6797 - val_loss: 1.3061 - val_accuracy: 0.6672\n",
      "Epoch 42/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2729 - accuracy: 0.6810 - val_loss: 1.5103 - val_accuracy: 0.5958\n",
      "Epoch 43/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.2729 - accuracy: 0.6815 - val_loss: 1.5095 - val_accuracy: 0.5955\n",
      "Epoch 44/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.2756 - accuracy: 0.6806 - val_loss: 1.3194 - val_accuracy: 0.6653\n",
      "Epoch 45/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.2733 - accuracy: 0.6830 - val_loss: 1.2965 - val_accuracy: 0.6752\n",
      "Epoch 46/50\n",
      "500/500 [==============================] - 64s 127ms/step - loss: 1.2667 - accuracy: 0.6848 - val_loss: 1.8098 - val_accuracy: 0.5615\n",
      "Epoch 47/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2594 - accuracy: 0.6848 - val_loss: 1.3129 - val_accuracy: 0.6603\n",
      "Epoch 48/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.2559 - accuracy: 0.6833 - val_loss: 1.6422 - val_accuracy: 0.5634\n",
      "Epoch 49/50\n",
      "500/500 [==============================] - 63s 126ms/step - loss: 1.2608 - accuracy: 0.6833 - val_loss: 1.3301 - val_accuracy: 0.6661\n",
      "Epoch 50/50\n",
      "500/500 [==============================] - 63s 127ms/step - loss: 1.2575 - accuracy: 0.6862 - val_loss: 1.3838 - val_accuracy: 0.6450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b3af285d30>"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Activation,  MaxPooling2D, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# # building the input vector from the 32x32 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# expand the input size by 3*3, so the input now is 96*96\n",
    "X_train = np.repeat(X_train,3,axis=1)\n",
    "X_train = np.repeat(X_train,3,axis=2)\n",
    "X_test = np.repeat(X_test,3,axis=1)\n",
    "X_test = np.repeat(X_test,3,axis=2)\n",
    "\n",
    "\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)\n",
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "L2_coeff = 0.0005\n",
    "# convolutional layer\n",
    "model.add(Conv2D(75, (3, 3), padding='same', activation='relu', input_shape=[96,96,3],kernel_regularizer=regularizers.l2(L2_coeff)))\n",
    "model.add(BatchNormalization())\n",
    "# convolutional layer\n",
    "model.add(Conv2D(50, kernel_size=(3,3), padding='same', activation='relu',kernel_regularizer=regularizers.l2(L2_coeff)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(50, kernel_size=(3,3), padding='same', activation='relu',kernel_regularizer=regularizers.l2(L2_coeff)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(250, activation='relu',kernel_regularizer=regularizers.l2(L2_coeff)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(250, activation='relu',kernel_regularizer=regularizers.l2(L2_coeff)))\n",
    "model.add(BatchNormalization())\n",
    "# output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# model.fit(X_train, Y_train, batch_size=250, epochs=50, validation_data=(X_test, Y_test))\n",
    "datagen = ImageDataGenerator(\n",
    "            rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=True)  # randomly flip images\n",
    "datagen.fit(X_train)\n",
    "model.fit(datagen.flow(X_train, Y_train, batch_size=100), steps_per_epoch=500, epochs=50, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otC2BmuaTeio",
    "outputId": "f2a5133a-69ad-4fb7-dd5b-0ae7037baa3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 32s 64ms/step - loss: 1.0286 - accuracy: 0.7634 - val_loss: 1.1439 - val_accuracy: 0.7179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b3488474f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, Y_train, batch_size=100, epochs=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6hCw9ijThbn"
   },
   "outputs": [],
   "source": [
    "model.save('simple_cnn_expanded3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inWbc1sYip5o",
    "outputId": "e00b33af-ef55-407f-bd21-ea8fbbe3e17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 96, 96, 75)        2100      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 96, 96, 75)        300       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 50)        33800     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 96, 96, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 50)        22550     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250)               7200250   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               62750     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 250)               1000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 7,326,660\n",
      "Trainable params: 7,325,310\n",
      "Non-trainable params: 1,350\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_simple_cnn_expanded3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
