{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_robust_vgg.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTrSf0soTX6g"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnVwUM3wTkql"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, Activation,  MaxPooling2D, BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
        "X_test = X_test.reshape(X_test.shape[0], 32, 32, 3)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "\n",
        "# import the models of vgg16 for continues training\n",
        "model = keras.models.load_model(\"./Models/vgg16.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VrzT-zeYfYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e70ce45-1e71-48cc-da9d-99ce069d7ef6"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.8260 - accuracy: 0.8756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.826046884059906, 0.8755999803543091]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y6gZkpqir0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ade640-9f6d-49d3-89b1-d785c45b0fb4"
      },
      "source": [
        "# train with imagedata generator\n",
        "datagen = ImageDataGenerator(\n",
        "            rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "            width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
        "            height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
        "            horizontal_flip=True,  # randomly flip images\n",
        "            vertical_flip=True)  # randomly flip images\n",
        "datagen.fit(X_train)\n",
        "batches = 0\n",
        "for x_batch, y_batch in datagen.flow(X_train, Y_train, batch_size=250):\n",
        "    adv_x_batch = fast_gradient_method(model,  x_batch, 0.2, norm=2, targeted=False, clip_max=1, clip_min = 0)\n",
        "    model.fit(np.concatenate((x_batch, adv_x_batch), axis=0),np.concatenate((y_batch, y_batch), axis=0), batch_size= 500, verbose = 0 )\n",
        "    batches +=1\n",
        "    \n",
        "    if batches >200:\n",
        "        break\n",
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 1.1113 - accuracy: 0.7964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.111286997795105, 0.7964000105857849]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MWInBy0PaNP",
        "outputId": "917d9d89-203c-4ab7-c93d-268d799f36ab"
      },
      "source": [
        "# continue training on trainning set instead of augmented set\n",
        "x_split = np.split(X_train,200)\n",
        "y_split = np.split(Y_train,200)\n",
        "for i in range(len(x_split)):\n",
        "    x_batch = x_split[i]\n",
        "    y_batch = y_split[i]\n",
        "    adv_x_batch = fast_gradient_method(model,  x_batch, 0.2, norm=2, targeted=False, clip_max=1, clip_min = 0)\n",
        "    model.fit(np.concatenate((x_batch, adv_x_batch), axis=0),np.concatenate((y_batch, y_batch), axis=0), batch_size= 500, verbose = 1 )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 130ms/step - loss: 0.9558 - accuracy: 0.8300\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.9473 - accuracy: 0.8360\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.9940 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9046 - accuracy: 0.8780\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.8459 - accuracy: 0.8740\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9330 - accuracy: 0.8680\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.8962 - accuracy: 0.8560\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.9356 - accuracy: 0.8380\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9081 - accuracy: 0.8480\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.8488 - accuracy: 0.8820\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.8687 - accuracy: 0.8600\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9379 - accuracy: 0.8620\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.9366 - accuracy: 0.8440\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9008 - accuracy: 0.8600\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.8444 - accuracy: 0.8680\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9011 - accuracy: 0.8540\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.1069 - accuracy: 0.7900\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0264 - accuracy: 0.8120\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0190 - accuracy: 0.8280\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.1775 - accuracy: 0.7680\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.2553 - accuracy: 0.7480\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1716 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0445 - accuracy: 0.8160\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0702 - accuracy: 0.7860\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1201 - accuracy: 0.7760\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0222 - accuracy: 0.8200\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.9767 - accuracy: 0.8240\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0894 - accuracy: 0.8120\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1098 - accuracy: 0.7740\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.9962 - accuracy: 0.8440\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0064 - accuracy: 0.8260\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0874 - accuracy: 0.8060\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0605 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.9655 - accuracy: 0.8200\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9961 - accuracy: 0.8200\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9831 - accuracy: 0.8080\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.1301 - accuracy: 0.7860\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9891 - accuracy: 0.8360\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9998 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0537 - accuracy: 0.7880\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0363 - accuracy: 0.7940\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 1.0219 - accuracy: 0.8260\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0539 - accuracy: 0.7980\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.0947 - accuracy: 0.7860\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1271 - accuracy: 0.7740\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.1452 - accuracy: 0.7880\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 1.0883 - accuracy: 0.8020\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9596 - accuracy: 0.8300\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.0805 - accuracy: 0.7980\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 1.1729 - accuracy: 0.7600\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0241 - accuracy: 0.8020\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0340 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0797 - accuracy: 0.8060\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.1355 - accuracy: 0.7660\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.1823 - accuracy: 0.7600\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.1682 - accuracy: 0.7660\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0384 - accuracy: 0.7980\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0271 - accuracy: 0.8040\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9884 - accuracy: 0.8240\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 1.0428 - accuracy: 0.7960\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 1.0020 - accuracy: 0.8200\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0809 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.0623 - accuracy: 0.7960\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.1477 - accuracy: 0.7740\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 1.0260 - accuracy: 0.8240\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0375 - accuracy: 0.8140\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0257 - accuracy: 0.8100\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.0296 - accuracy: 0.8160\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9975 - accuracy: 0.8360\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0936 - accuracy: 0.7940\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0847 - accuracy: 0.8080\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0150 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0043 - accuracy: 0.8260\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0664 - accuracy: 0.8220\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0874 - accuracy: 0.8080\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.9735 - accuracy: 0.8360\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0575 - accuracy: 0.7960\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0169 - accuracy: 0.8200\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0625 - accuracy: 0.8120\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.1077 - accuracy: 0.8060\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0042 - accuracy: 0.8140\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0388 - accuracy: 0.8020\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9702 - accuracy: 0.8280\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0415 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.0164 - accuracy: 0.8320\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 1.0368 - accuracy: 0.7920\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0670 - accuracy: 0.8140\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0702 - accuracy: 0.8080\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0042 - accuracy: 0.7820\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0999 - accuracy: 0.7820\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0679 - accuracy: 0.7940\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0581 - accuracy: 0.8080\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0437 - accuracy: 0.8120\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9621 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.0412 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9759 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9508 - accuracy: 0.8420\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.0296 - accuracy: 0.8140\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0269 - accuracy: 0.7980\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.0944 - accuracy: 0.8020\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0398 - accuracy: 0.8020\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.1059 - accuracy: 0.7680\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0669 - accuracy: 0.7960\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9390 - accuracy: 0.8460\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9071 - accuracy: 0.8560\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.8882 - accuracy: 0.8620\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0182 - accuracy: 0.7940\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1534 - accuracy: 0.7660\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.1413 - accuracy: 0.7960\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.8978 - accuracy: 0.8580\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9642 - accuracy: 0.8160\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0472 - accuracy: 0.8300\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9419 - accuracy: 0.8420\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0186 - accuracy: 0.7840\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 1.0936 - accuracy: 0.7780\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9230 - accuracy: 0.8440\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9975 - accuracy: 0.8040\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.9424 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0171 - accuracy: 0.8240\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.9613 - accuracy: 0.8400\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.1124 - accuracy: 0.7660\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9342 - accuracy: 0.8460\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0630 - accuracy: 0.7900\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9927 - accuracy: 0.8040\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.9962 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 1.0697 - accuracy: 0.7980\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9712 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0466 - accuracy: 0.7900\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0802 - accuracy: 0.7800\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9718 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0477 - accuracy: 0.8100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.1670 - accuracy: 0.7440\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0477 - accuracy: 0.8220\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9593 - accuracy: 0.8280\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0913 - accuracy: 0.7780\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0748 - accuracy: 0.7940\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0203 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0091 - accuracy: 0.8040\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0120 - accuracy: 0.8020\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9717 - accuracy: 0.8240\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0350 - accuracy: 0.8260\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0228 - accuracy: 0.8060\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.9170 - accuracy: 0.8480\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9816 - accuracy: 0.8280\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0890 - accuracy: 0.7860\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9503 - accuracy: 0.8280\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0306 - accuracy: 0.8060\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0769 - accuracy: 0.7840\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.9657 - accuracy: 0.8160\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9675 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9735 - accuracy: 0.8380\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.1122 - accuracy: 0.7860\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0169 - accuracy: 0.8300\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.9843 - accuracy: 0.8100\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9781 - accuracy: 0.8140\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9242 - accuracy: 0.8420\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.9074 - accuracy: 0.8500\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9627 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.9476 - accuracy: 0.8360\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.1072 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9442 - accuracy: 0.8280\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9817 - accuracy: 0.8160\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0286 - accuracy: 0.8100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 1.0088 - accuracy: 0.8300\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9358 - accuracy: 0.8320\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0032 - accuracy: 0.8060\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0499 - accuracy: 0.8120\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9939 - accuracy: 0.8360\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9331 - accuracy: 0.8560\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9056 - accuracy: 0.8520\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.9960 - accuracy: 0.8040\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 1.0077 - accuracy: 0.8000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.9364 - accuracy: 0.8400\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.1487 - accuracy: 0.7560\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 1.0214 - accuracy: 0.8100\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9331 - accuracy: 0.8520\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9567 - accuracy: 0.8240\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.9626 - accuracy: 0.8260\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0012 - accuracy: 0.8140\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.1122 - accuracy: 0.7960\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.9344 - accuracy: 0.8460\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9434 - accuracy: 0.8440\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.8866 - accuracy: 0.8420\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 1.0848 - accuracy: 0.7880\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.9475 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 1.0420 - accuracy: 0.7920\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9780 - accuracy: 0.8120\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.9139 - accuracy: 0.8340\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9856 - accuracy: 0.8180\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9464 - accuracy: 0.8300\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.9241 - accuracy: 0.8320\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9761 - accuracy: 0.8460\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.9398 - accuracy: 0.8380\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.9176 - accuracy: 0.8420\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 1.0009 - accuracy: 0.8220\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 0.8960 - accuracy: 0.8520\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.9798 - accuracy: 0.8100\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 1.0946 - accuracy: 0.7940\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.9978 - accuracy: 0.7980\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.8558 - accuracy: 0.8620\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq4LRi71itzh",
        "outputId": "e2165b0e-9e18-4a77-eeae-be7406f1158c"
      },
      "source": [
        "model.evaluate(X_test,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.8836 - accuracy: 0.8602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8835809826850891, 0.8601999878883362]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLbBvZKbzAyZ"
      },
      "source": [
        "model.save('robust_vgg16.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}